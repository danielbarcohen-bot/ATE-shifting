{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"generated data - checking models ability to re-construct transformations\",\n",
    "   \"id\": \"844b84a7a727b499\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"np.random.seed(42)\\n\",\n",
    "    \"n = 3000\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ── Raw covariates ────────────────────────────────────────────────────────────\\n\",\n",
    "    \"\\n\",\n",
    "    \"# c1: log-normal (right-skewed). Min-max norm tames extreme values.\\n\",\n",
    "    \"c1 = np.random.lognormal(mean=0, sigma=1.0, size=n)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# c2: uniform [0,100]. The TRUE relationship with outcome/propensity is\\n\",\n",
    "    \"# U-SHAPED (quadratic): extreme values of c2 are associated with high\\n\",\n",
    "    \"# treatment probability and high baseline outcome.\\n\",\n",
    "    \"# Equal-width bins (used as dummies in OLS) can approximate this step-wise;\\n\",\n",
    "    \"# raw linear c2 cannot (the U-shape is symmetric → linear term ≈ 0).\\n\",\n",
    "    \"c2 = np.random.uniform(0, 100, n)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# c3: normal contaminated with extreme outliers (~7% of observations).\\n\",\n",
    "    \"# Outliers inflate the std so the raw z-score is compressed for normal obs.\\n\",\n",
    "    \"# Clipping at ±3 removes their influence and restores a well-scaled covariate.\\n\",\n",
    "    \"c3 = np.random.normal(0, 1, n)\\n\",\n",
    "    \"contam_idx = np.random.choice(n, size=200, replace=False)\\n\",\n",
    "    \"c3[contam_idx] = np.random.uniform(20, 50, 200)\\n\",\n",
    "    \"c4, c5, c6, c7, c8, c9 = (np.random.uniform(0, 100, n) for _ in range(6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ── Treatment propensity (confounded via c2 U-shape and c3) ──────────────────\\n\",\n",
    "    \"log_odds = -1.0 + 5.0 * c2 ** 2 - 3.0 * c3 + 1.0 * c1 + c4 - c5 + c6 - c7 + c8 - c9\\n\",\n",
    "    \"prob_treat = 1 / (1 + np.exp(-log_odds))\\n\",\n",
    "    \"treatment = np.random.binomial(1, prob_treat, n)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ── True (heterogeneous) treatment effect — linear in transformed features ────\\n\",\n",
    "    \"true_te = 2.0 + 2.0 * c1 + 3.0 * c2 + 2.0 * c3\\n\",\n",
    "    \"true_ATE = true_te.mean()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ── Outcome ───────────────────────────────────────────────────────────────────\\n\",\n",
    "    \"noise = np.random.normal(0, 1, n)\\n\",\n",
    "    \"y = (\\n\",\n",
    "    \"        1.0\\n\",\n",
    "    \"        + 2.0 * c1\\n\",\n",
    "    \"        + 6.0 * c2 ** 2  # U-shaped confounding: raw linear c2 can't absorb this\\n\",\n",
    "    \"        - 2.5 * c3 + c4 - c5 + c6 - c7 + c8 - c9\\n\",\n",
    "    \"        + treatment * true_te\\n\",\n",
    "    \"        + noise\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ── Save dataset ──────────────────────────────────────────────────────────────\\n\",\n",
    "    \"df = pd.DataFrame({\\n\",\n",
    "    \"    'outcome': y,\\n\",\n",
    "    \"    'treatment': treatment,\\n\",\n",
    "    \"    # Raw covariates\\n\",\n",
    "    \"    'c1': c1,\\n\",\n",
    "    \"    'c2': c2,\\n\",\n",
    "    \"    'c3': c3,\\n\",\n",
    "    \"    'c4': c4,\\n\",\n",
    "    \"    'c5': c5,\\n\",\n",
    "    \"    'c6': c6,\\n\",\n",
    "    \"    'c7': c7,\\n\",\n",
    "    \"    'c8': c8,\\n\",\n",
    "    \"    'c9': c9\\n\",\n",
    "    \"})\"\n",
    "   ],\n",
    "   \"id\": \"ebcd6c8012743d84\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from utils import calculate_ate_linear_regression_lstsq, apply_data_preparations_seq\\n\",\n",
    "    \"from experiments import large_data_transformations\\n\",\n",
    "    \"confunders = [f\\\"c{i}\\\" for i in range(1,10)]\\n\",\n",
    "    \"print(f\\\"ATE before: {calculate_ate_linear_regression_lstsq(df, 'treatment', 'outcome', confunders)}\\\")\\n\",\n",
    "    \"applied_seq = (('bin_equal_frequency_2', 'c2'), ('bin_equal_width_2', 'c3'), ('norm_min_max', 'c4'))#(('bin_equal_frequency_2', 'c3'), ('bin_equal_frequency_2', 'c1'), ('norm_log', 'c2'))\\n\",\n",
    "    \"treated_df = apply_data_preparations_seq(df, applied_seq, large_data_transformations)\\n\",\n",
    "    \"print(f\\\"ATE after: {calculate_ate_linear_regression_lstsq(treated_df, 'treatment', 'outcome', confunders)}\\\")\"\n",
    "   ],\n",
    "   \"id\": \"726d61388765ea64\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from search_methods.probe_ATE_search import ProbeATESearch\\n\",\n",
    "    \"from search_methods.prune_ATE_search import PruneATESearch\\n\",\n",
    "    \"from experiments import large_data_transformations\\n\",\n",
    "    \"df.rename(columns={'y': 'outcome'}, inplace=True)\\n\",\n",
    "    \"ProbeATESearch().search(df=df, common_causes=[f\\\"c{i}\\\" for i in range(1,10)],\\n\",\n",
    "    \"                                       target_ate=5070,\\n\",\n",
    "    \"                                       epsilon=1,\\n\",\n",
    "    \"                                       max_seq_length=10, transformations_dict=large_data_transformations)\"\n",
    "   ],\n",
    "   \"id\": \"9f277efc228bbb31\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "36557336fdeade34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "sensitivity analysis - refutation",
   "id": "349fa8f18eb7e480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dowhy import CausalModel\n",
    "from experiments import df_twins_no_missing_values, df_acs_no_missing_values"
   ],
   "id": "b4e25e8ddbaccdc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def run_all_refutations(model, identified_estimand, estimate):\n",
    "    refutation_results = []\n",
    "\n",
    "    methods = [\n",
    "        {\"name\": \"random_common_cause\", \"label\": \"Add Random Common Cause\"},\n",
    "        {\"name\": \"placebo_treatment_refuter\", \"label\": \"Placebo Treatment\"},\n",
    "        {\"name\": \"dummy_outcome_refuter\", \"label\": \"Dummy Outcome\"},\n",
    "        {\"name\": \"data_subset_refuter\", \"label\": \"Data Subsets Validation\", \"kwargs\": {\"subset_fraction\": 0.9}},\n",
    "        {\"name\": \"bootstrap_refuter\", \"label\": \"Bootstrap Validation\", \"kwargs\": {\"num_simulations\": 100}},\n",
    "        {\"name\": \"add_unobserved_common_cause\", \"label\": \"Add Unobserved Common Cause\"}\n",
    "    ]\n",
    "\n",
    "    for m in methods:\n",
    "        try:\n",
    "            print(f\"Running {m['label']}...\")\n",
    "            res = model.refute_estimate(\n",
    "                identified_estimand,\n",
    "                estimate,\n",
    "                method_name=m['name'],\n",
    "                **m.get(\"kwargs\", {})\n",
    "            )\n",
    "\n",
    "            # --- תיקון השגיאה: טיפול במקרה שמוחזרת רשימה ---\n",
    "            if isinstance(res, list):\n",
    "                res = res[0]\n",
    "            # ---------------------------------------------\n",
    "            print(res.refutation_result)\n",
    "            p_val = res.refutation_result.get('p_value')\n",
    "\n",
    "            # בבדיקות אלו, p-value נמוך מ-0.05 מעיד על חוסר יציבות (FAIL)\n",
    "            status = \"PASS\" if (p_val is not None and p_val >= 0.05) else \"FAIL\"\n",
    "\n",
    "            refutation_results.append({\n",
    "                \"Method\": m['label'],\n",
    "                \"p-value\": round(p_val, 4) if isinstance(p_val, (int, float)) else p_val,\n",
    "                \"Result\": status\n",
    "            })\n",
    "        except Exception as e:\n",
    "            refutation_results.append({\n",
    "                \"Method\": m['label'],\n",
    "                \"p-value\": \"Error\",\n",
    "                \"Result\": f\"Error: {str(e)}\"\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(refutation_results)\n"
   ],
   "id": "dcc6c9c76322a2bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_twins=CausalModel(\n",
    "        data = df_twins_no_missing_values,\n",
    "        treatment='treatment',\n",
    "        outcome='outcome',\n",
    "        common_causes=df_twins_no_missing_values.columns.difference([\"treatment\", \"outcome\"]).tolist()\n",
    "        )\n",
    "identified_estimand_twins = model_twins.identify_effect(proceed_when_unidentifiable=True)\n",
    "estimate_twins = model_twins.estimate_effect(identified_estimand_twins,method_name=\"backdoor.linear_regression\")\n",
    "\n",
    "run_all_refutations(model_twins, identified_estimand_twins, estimate_twins)"
   ],
   "id": "b4512a257c980bf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_acs=CausalModel(\n",
    "        data = df_acs_no_missing_values,\n",
    "        treatment='treatment',\n",
    "        outcome='outcome',\n",
    "        common_causes=df_acs_no_missing_values.columns.difference([\"treatment\", \"outcome\"]).tolist()\n",
    "        )\n",
    "identified_estimand_acs = model_acs.identify_effect(proceed_when_unidentifiable=True)\n",
    "estimate_acs = model_acs.estimate_effect(identified_estimand_acs,method_name=\"backdoor.linear_regression\")\n",
    "\n",
    "run_all_refutations(model_acs, identified_estimand_acs, estimate_acs)"
   ],
   "id": "b1eda02bda466883"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "refutation = model_twins.refute_estimate(\n",
    "    identified_estimand_twins,\n",
    "    estimate_twins,\n",
    "    method_name=\"add_unobserved_common_cause\",\n",
    "    confounders_effect_on_treatment=\"linear\",\n",
    "    confounders_effect_on_outcome=\"linear\"\n",
    ")\n",
    "print(refutation)\n",
    "\n",
    "refutation = model_acs.refute_estimate(\n",
    "    identified_estimand_acs,\n",
    "    estimate_acs,\n",
    "    method_name=\"add_unobserved_common_cause\",\n",
    "    confounders_effect_on_treatment=\"linear\",\n",
    "    confounders_effect_on_outcome=\"linear\"\n",
    ")\n",
    "print(refutation)"
   ],
   "id": "4018ad3df3864ed4"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
